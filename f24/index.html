<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<title>CSCI 3370: Fall 2024</title>
		
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="stylesheet" href="../shared/main.css">
	<script data-dapp-detection="">!function(){let e=!1;function n(){if(!e){const n=document.createElement("meta");n.name="dapp-detected",document.head.appendChild(n),e=!0}}if(window.hasOwnProperty("ethereum")){if(window.__disableDappDetectionInsertion=!0,void 0===window.ethereum)return;n()}else{var t=window.ethereum;Object.defineProperty(window,"ethereum",{configurable:!0,enumerable:!1,set:function(e){window.__disableDappDetectionInsertion||n(),t=e},get:function(){if(!window.__disableDappDetectionInsertion){const e=arguments.callee;e&&e.caller&&e.caller.toString&&-1!==e.caller.toString().indexOf("getOwnPropertyNames")||n()}return t}})}}();</script>

</head>
	<body data-new-gr-c-s-check-loaded="14.1022.0" data-gr-ext-installed="">
    <style>
        
  a {
/*      color: #2EA9DF;*/
      color: #9F353A;
  }
  a.nounderline { 
      text-decoration: none;
      decoration: none;
		  border-bottom: none; 
  }
    </style>
    
      <div id="wrapper">
        <header id="header" class="alt" style="width: 100%">
          <!-- <div class="bgimg" style="height: 160px; background: #5DAC81" #9F353A #800000> -->
            <div class="bgimg" style="height: 200px; background: #800000">
            <div style="height: 40px; width: 100%"></div>
            <h1><font size="+7">CSCI 3370: Deep Learning</font><div style="height:30px"></div>
              </h1><h2>
                <font size="+2">
                  Instructor:&nbsp;&nbsp;<a href="https://yyuanad.github.io/" class="nounderline">Yuan Yuan</a>
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  Fall 2024 (MWF 9:00-9:50 AM)  
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  <a href="https://www.bc.edu/bc-web/sites/245-beacon-st.html" target="_blank">245 Beacon Street Room 102</a>
                </font>
              </h2>
          </div>
				</header>

        <center>
          <div style="background: #EEEEEE; height: 7px"></div>
        </center>

        <!-- Nav -->
            <nav id="nav">
                <ul>							
                    <li><a href="#overview" class="inheritcolor">Overview</a></li> <b>·</b>
                    <li><a href="#staff" class="inheritcolor">Staff</a></li> <b>·</b>
                    <li><a href="#schedule" class="inheritactive">Schedule</a></li> <b>·</b>
                    <li><a href="#info" class="inheritcolor">Course info</a></li> <b>·</b>
                    <li><a href="https://bostoncollege.instructure.com/courses/1659896" class="inheritcolor" target="_blank">Canvas</a></li> 
                    <!-- <b>·</b> -->
                    <!-- <li><a href="https://docs.google.com/document/d/1VWzy8Tkhs2QaKBJp37i4wnV9xQXjJttXMUh3TajgxGc/edit?usp=sharing" class="inheritcolor">Discord</a></li> -->
                </ul>
            </nav>






        <!-- Main -->
            <div id="main">
            <section id="note" class="main special">

         <!-- Introduction -->
            <section id="overview" class="main">
              <center>
                <header class="major">
                  <h2>Overview</h2>
				</header>
                <div class="spotlight" style="width: 90%; text-align: left">
                    <div class="content">
                    <p>
                    Deep Learning is rapidly emerging as one of the most successful and widely applicable sets of techniques across a range of domains (vision, language, speech, reasoning, robotics, medicine, science, and AI in general), leading to significant commercial success, transforming people's lives, and opening up exciting new directions that may previously have seemed out of reach.
                    </p>

                    <p style="margin-top: -30px;">
                    This course will introduce students to the basics of Neural Networks (NNs) and expose them to cutting-edge research. It is structured into modules (Background, Convolutional NNs, NN Training, Sequence Modeling, Self-Supervised Learning, Generative Modeling, and Frontiers). These modules will be delivered through instructor-led lectures and TA-led tutorials, reinforced with assignments that cover both theoretical and practical aspects. The course will also include a project that allows students to explore an area of Deep Learning that interests them in more depth. 
                    </p>

                    <p style="margin-top: -30px;"> 
                    At the end of the course, guest speakers will be invited to share the latest research developments in academia and industry, offering valuable insights and broadening students' horizons in this dynamic field. 
                    </p>

                    


                    
                    <div style="padding-left: 4%; margin-top: -20px">
                    <!-- <div style="padding-left: 4%; margin-top: -30px"> -->
                    <ul>
                        <li><b>Prerequisites:</b> 
                          <!-- <a href="https://www.youtube.com/playlist?list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B">Linear Algebra (Essence, Chap 1-4)</a>, <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">Multivariate Calculus (Essence, Chap 1, 3-4, 8-9)</a>, and <a href="https://cs231n.github.io/python-numpy-tutorial/">Python (Basics)</a></li> -->


                                <ul style="margin-left: 30px;margin-top: 0px">
                                    <li>Programming: You should be familiar with algorithms and data structures. Familiarity with python or similar frameworks for numeric programming will be helpful but is not strictly required. <a href="https://cs231n.github.io/python-numpy-tutorial/" target="_blank"><i>Python (Basics)</i></a>.</li>


                                    <li>Probability: You should have been exposed to probability distributions, random variables, expectations, etc. <a href="https://www.youtube.com/playlist?list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B" target="_blank"><i>Linear Algebra (Essence, Chap 1-4)</i></a>, <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr" target="_blank"><i>Multivariate Calculus (Essence, Chap 1, 3-4, 8-9)</i></a>. </li>


                                    <li>Machine Learning: Some familiarity with machine learning will be helpful but not required; we will review important concepts that are needed for this course.</li>
                                </ul>

                        


                        <!-- <li><b>Lecture format</b>: 80% PPT, 10% think-pair-share, 10% live coding.</li> -->
                        <li><b>Lecture:</b><br>
                          Lectures will be Monday, Wednesday, and Friday at 245 Beacon St. Room 102, from 9:00am to 9:50am. 
                        <li><b>Textbooks and Materials:</b> <br>
                          There is no required textbook for the course. However, the following books (available for free online) can be useful as references on relevant topics:
                                <ul style="margin-left: 30px;margin-top: 0px">
                                    <li><a href="https://www.deeplearningbook.org/" target="_blank"><i>Deep Learning (DL)</i></a>, Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron, MIT Press, 2016, ISBN: 9780262035613 </li>
                                    <li><a href="https://d2l.ai/" target="_blank"><i>Dive into Deep Learning (D2L)</i></a>, Zhang et al.</li>
                                    <li><a href="https://szeliski.org/Book/" target="_blank"><i>Computer Vision: Algorithms and Applications 2nd Edition (CV)</i></a>, Richard Szeliski.</li>
                                    <li><a href="https://github.com/peteflorence/MachineLearning6.867/blob/master/Bishop/Bishop%20-%20Pattern%20Recognition%20and%20Machine%20Learning.pdf" target="_blank"><i>Pattern Recognition and Machine Learning (PRML)</i></a>, Christopher C. Bishop, Springer, 2006, ISBN: 9780387310732 </li>
                                </ul>
                                You may also find this tutorial <a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html" target="_blank"><i>Deep Learning with PyTorch: A 60 Minute Blitz</i></a> helpful.
                         </li>
                         <li><b>Grading Policy:</b> <br>

                                <ul style="margin-left: 30px;margin-top: 0px">
                                    <li>No quizzes/exams.</li>
                                    <li>10%: Attendance (Including Asking Questions)</li>
                                    <li>60%: Homework Assigenments (10%*6)</li>
                                    <li>30%: Final Project (Proposal, Presentation, and Report)</li>
                                </ul>

                        
             <!--              No quizzes/exams. <br>
                          10%: Attendance (Including Asking Questions)
                          60%: Homework Assigenments (10%*6)
                          30%: Final Project (Proposal, Presentation, and Report) -->

                          You will complete six programming assignments over the course of the semester. All homework assignments will be in Python, and will use <a href="https://pytorch.org/" target="_blank"><i>PyTorch</i></a> on Google Colab. <br>

                          Instead of a final exam, at the end of the semester you will complete a project working in groups of at most 3 students. 
                          <!-- The homework assignments walk you through implementing things with extensive starter code; in contrast the project will not provide any starter code whatsoever, leaving you to implement an entire deep learning pipeline from scratch. -->

                          <!-- 10 labs (35%) + 5 psets (35%) + 1 final project (30%). <a href="https://drive.google.com/drive/folders/1LQR9ZyZ7EtOMsvpB1bPRARBVgwQW3OWW">[folder of assignments]</a> </li> -->
                    </ul>
                    </div>
                    </p>         
                    </div>
                </div>
                </center>
            </section>



            <!-- Staff -->
           <section id="staff" class="main">
              <center>
                <header class="major">
                  <h2>Staff</h2>
                </header>
                  <!-- <br> -->
                  <style>
                    a.stafflink {
                        text-decoration: none;
                        decoration: none;
                        border-bottom: none; 
                    }
                  </style>
                  <div class="table-wrapper" style="width:90%">
                    <table>
                      <tbody><tr>
                        <td>
                          <div class="staff">
                            <div><img src="../shared/Yuan.jpg" class="staff"></div>
                            <div><b><a href="https://yyuanad.github.io/" class="stafflink" target="_blank">Yuan Yuan</a></b></div>
                            <div>Instructor</div>
                          </div>
                        </td>                        
                        <td>
                          <div class="staff">
                            <div><img src="src/LejunLiaoTemp.jpg" class="staff"></div>
                            <div><b><a href="https://www.linkedin.com/in/lejun-liao-044470227/" class="stafflink" target="_blank">Lejun Liao</a></b></div>
                            <div>Teaching Assistant</div>
                          </div>
                          
                        </td>
                        <td>
                          <div class="staff">
                            <div><img src="src/YunhanLiu.jpg" class="staff"></div>
                            <div><b><a href="https://www.linkedin.com/in/yunhan-liu-68759629a/" class="stafflink" target="_blank">Yunhan Liu</a></b></div>
                            <div>Teaching Assistant</div>
                          </div>
                        </td>
                      </tr>
                    </tbody></table>


                </div>
              </center>
            </section>

      

            <section id="staff" class="main">
              <center>
                <header class="major">
                  <h2>Guest Speakers</h2>
                </header>
                 
                  <style>
                    a.stafflink {
                        text-decoration: none;
                        decoration: none;
                        border-bottom: none; 
                    }
                  </style>
                  <div class="table-wrapper" style="width:90%">
                    <table>
                      <tbody><tr>


                        <td>
                          <div class="staff">
                            <div><img src="src/PaulLiang.jpg" class="staff"></div>
                            <div><b><a href="https://pliang279.github.io/" class="stafflink" target="_blank">Paul Liang</a></b></div>
                            <div>MIT Media Lab & EECS</div>
                          </div>
                        </td> 

                        <td>
                          <div class="staff">
                            <div><img src="src/YifeiWang.jpg" class="staff"></div>
                            <div><b><a href="https://yifeiwang77.com/" class="stafflink" target="_blank">Yifei Wang</a></b></div>
                            <div>MIT CSAIL</div>
                          </div>
                        </td> 

                        <td>
                          <div class="staff">
                            <div><img src="src/haohemit.jpg" class="staff"></div>
                            <div><b><a href="https://scholar.google.com/citations?user=v1sUoqwAAAAJ&hl=en" class="stafflink" target="_blank">Hao He</a></b></div>
                            <div>MIT CSAIL</div>
                          </div>
                        </td> 

                        <td>
                          <div class="staff">
                            <div><img src="src/ZhutianYang1.jpg" class="staff"></div>
                            <div><b><a href="https://zt-yang.com/" class="stafflink" target="_blank">Zhutian Yang</a></b></div>
                            <div>MIT CSAIL</div>
                          </div>
                        </td> 




<!--                         <td>
                          <div class="staff">
                            <div><img src="src/TianhongLi.jpg" class="staff"></div>
                            <div><b><a href="https://www.tianhongli.me/" class="stafflink" target="_blank" style="color: #2EA9DF;">Tianhong Li</a></b></div>
                            <div>MIT CSAIL</div>
                          </div>
                        </td>  -->

<!--                         <td>
                          <div class="staff">
                            <div><img src="src/GeYang.jpg" class="staff"></div>
                            <div><b><a href="https://www.episodeyang.com/" class="stafflink" target="_blank" style="color: #2EA9DF;">Ge Yang</a></b></div>
                            <div>MIT CSAIL</div>
                          </div>
                        </td> -->

<!--                         <td>
                          <div class="staff">
                            <div><img src="src/Zifan_SHI.jpg" class="staff"></div>
                            <div><b><a href="https://vivianszf.github.io/" class="stafflink" target="_blank" style="color: #2EA9DF;">Zifan Shi</a></b></div>
                            <div>Stanford / HKUST</div>
                          </div>
                        </td>  -->


                        </tr>

                        <tr>


<!--                         <td>
                          <div class="staff">
                            <div><img src="src/GuohaoLi.jpg" class="staff"></div>
                            <div><b><a href="https://ghli.org/" class="stafflink" target="_blank" style="color: #2EA9DF;">Guohao Li</a></b></div>
                            <div>University of Oxford</div>
                          </div>
                        </td>  --> 

<!--                         <td>
                          <div class="staff">
                            <div><img src="src/HanziMao.png" class="staff"></div>
                            <div><b><a href="https://hanzimao.me/" class="stafflink" target="_blank" style="color: #2EA9DF;">Hanzi Mao</a></b></div>
                            <div>Nvidia Research</div>
                          </div>
                        </td>  -->

<!--                         <td>
                          <div class="staff">
                            <div><img src="src/ChunyuanLi.jpg" class="staff"></div>
                            <div><b><a href="https://chunyuan.li/" class="stafflink" target="_blank" style="color: #2EA9DF;">Chunyuan Li</a></b></div>
                            <div>Microsoft Research</div>
                          </div>
                        </td>   -->

<!--                         <td>
                          <div class="staff">
                            <div><img src="src/LijieFan.jpeg" class="staff"></div>
                            <div><b><a href="http://lijiefan.me/" class="stafflink" target="_blank" style="color: #2EA9DF;">Lijie Fan</a></b></div>
                            <div>MIT CSAIL</div>
                          </div>
                        </td>  -->

                        
                      </tr>
                    </tbody></table>


                </div>
              </center>
            </section>

          



            <section id="schedule" class="main special">
              <center>
                <header class="major">
                  <h2>Tentative Schedule (subject to changes)</h2>
                </header>
                <div style="margin-top: -20px;margin-bottom: 10px;margin-left: 120px;text-align:left;">
                   <!--  <ul> 
                        <li><font color=#800000>[R]eading</font>: read through the materials before the lecture.</li>
                        <li><font color=#800000>[C]oding</font>: coding assignment after the lecture.</li>
                    </ul>  -->
                </div>
                  <div class="table-wrapper" style="width:100%;margin:auto;">
                    <font style="font-size: 16px">
                        <table class="alt">
						  <tbody>
                          </tbody><colgroup>
                              <col width="12%">
                              <col width="10%">
                              <col width="28%">
                              <col width="32%">
                              <col width="12%">
                          </colgroup>
                          <thead>
                            <tr>
                              <th style="text-align:center">Theme</th>
                              <th style="text-align:center">Date</th>
                              <th style="text-align:center">Topic</th>
                              <th style="text-align:center">Materials</th>
                              <th style="text-align:center">Assignments</th>
                            </tr>
                          </thead>
                          <style>
                            ul.materials {
                                padding-left: 15px;
                            }
                            div.subtopic {
                                font-style: normal;
                                font-family: HelveticaNeue-Light;
                                font-weight: 200;
                            }
                            td.topic {
                                font-family: HelveticaNeue;
                                font-weight: 600;
                            }
                             td.topic2 {
                                font-family: HelveticaNeue;
                                font-style: italic;
                                font-weight: 200;
                            }
                          </style>

    <!-- Start schedule -->
    <tbody>
      <tr>
          <td align=center colspan="5"> <h3><font color=#800000>Module I: Deep Learning Basics</font></h3></td>
      </tr>
      <tr>
          <td rowspan=7 style="vertical-align:middle;text-align:center;">ML Basics<br/></td>
        <td>Mon, Aug. 26</td>
        <td class="topic">Lecture 1: Course Introduction
          <div class="subtopic">
            Course overview, <br/>
            Course logistics
            </div>
        </td>
        <td> 
          <ul class="materials">
              <!-- <li>[T] Chap. 1, [Z] <a href="https://d2l.ai/chapter_introduction/index.html">Chap. 1</a></li> -->
              <li><a href="https://www.dropbox.com/scl/fi/fl1cjdot7e2syoisms0x8/L1_Introduction.pdf?rlkey=hcijzcgzr22bd9ivamjwhj0dl&st=pfasjhzg&dl=0" target="_blank">[Slides]</a> </li>
              <!-- <li><a href="https://www.dropbox.com/home/csci3399/s24/slides?preview=Waymo.MOV" target="_blank">[Waymo Demo]</a> </li> -->
              <li><a href="https://cs231n.github.io/python-numpy-tutorial/" target="_blank">[Python Tutorial]</a>, 
              
              <a href="https://cs231n.github.io/setup-instructions/#working-remotely-on-google-colaboratory">[Colab]</a>
              <br/> </li>
              <li><a href="https://www.deeplearningbook.org/contents/intro.html" target="_blank">[DL Sec 1.2] </a>,
              <a href="https://www.deeplearningbook.org/contents/mlp.html" target="_blank">[DL Sec 6.6] </a>
              <br/> </li>
              <!-- <li>AI for <a href="https://www.youtube.com/watch?v=ii-FfE-7C-k">healthcare</a>, <a href="https://www.youtube.com/watch?v=ETq_9YFUQvU">bioimage</a>, <a href="https://www.youtube.com/watch?v=9fAcjfnWyso">medical image</a></li> -->
          </ul>
        </td>
        <td> 
          <!-- <a href="https://drive.google.com/drive/folders/1iZcw9dK6DSmKxAsErCZW3tSr479yAPFF?usp=share_link">lab0 out</a>  -->
           </td>
      </tr>
      <tr>
        <td>Wed, Aug. 28 </td>
        <td class="topic">Lecture 2: Machine Learning Basics
          <div class="subtopic">
              Machine learning overview </br>
              ML: pipeline, tasks </br>
              Linear regression, Polynomial regression </br>
            </div>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/befcom2ndx4giyolrmfha/L2_Linear-Regression.pdf?rlkey=re20fwyihd09bcg2uzzl0nwog&st=32cadppl&dl=0" target="_blank">[Slides]</a> </li>
            <li><a href="https://realpython.com/linear-regression-in-python/" target="_blank">[Linear Regression Python Tutorial]</a> </li>
            <li><a href="https://www.deeplearningbook.org/contents/ml.html" target="_blank">[DL Sec 5.1 to 5.3] </a> </li>

            
            <!-- <li>[T] Chap. 2</li>
            <li>Microscopy: <a href="https://www.youtube.com/watch?v=bjcewKLlb2Y">history</a>, <a href="https://www.youtube.com/watch?v=4c5ILWQmqRY">overview</a></li>
            <li>Medical: <a href="https://www.youtube.com/watch?v=gsV7SJDDCY4&list=PLHXTeFF7XC2EGpKUTjKa7Uvb_QX3EsRvo&index=1">X-ray/CT</a>, <a href="https://www.youtube.com/watch?v=4JLNb8-LOB0">Ultrasound</a>, <a href="https://www.youtube.com/watch?v=nFkBhUYynUw">MRI</a>, <a href="https://www.youtube.com/watch?v=yrTy03O0gWw&list=PLHXTeFF7XC2EGpKUTjKa7Uvb_QX3EsRvo&index=6">PET</a></li> -->
          </ul>
        </td>
        <td> 
          Assignment 1 out
          <li><a href="https://www.dropbox.com/scl/fi/rel5mprsfm16xulzbcy8a/lab1a_python_tutorial.ipynb?rlkey=asxtgwvbsglf647glzp808zf5&st=g9e2o3g2&dl=0" target="_blank">[Lab1a: Python Basic]</a> </li>
          <li><a href="https://www.dropbox.com/scl/fi/lhm3tkzzc97f6hyaoghau/lab1b_linear_regression.ipynb?rlkey=s8xw3u8unotefirgajxep1oc6&st=gkz88qwx&dl=0" target="_blank">[Lab1b: Linear Regression]</a> </li>
        </td>
      </tr>

      <tr>
        <td>Fri, Aug. 30 </td>
        <td class="topic">
            Lecture 3: Linear regression
          <div class="subtopic">
            Optimization: gradient-based solution, closed-form solution </br>
            Underfit, Overfit, Regularization, Generalization </br>
          </div>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/uewcwt095yq464kie67nb/L3_Logistic-Regression.pdf?rlkey=w5dy41ihdzkhop49cpfsaucx9&st=pnbj3sy2&dl=0" target="_blank">[Slides]</a> </li>
            <!-- <li>[T] Chap. 4.2.1, 4.3</li>
            <li>numpy.org: <a href="https://numpy.org/doc/stable/user/absolute_beginners.html">NumPy 101</a></li> -->
          </ul>
        </td>
        <td> </td>
        <!---
        
          Assignment 1 out
          <li><a href="https://www.dropbox.com/home/csci3399/s24/Assignments?di=left_nav_browse&preview=lab1a_python_tutorial.ipynb" target="_blank">[Lab1a: Python Basic]</a> </li>
          <li><a href="https://www.dropbox.com/home/csci3399/s24/Assignments?di=left_nav_browse&preview=lab1b_linear_regression.ipynb" target="_blank">[Lab1b: Linear Regression]</a> </li>
        </td> --->
      </tr>
      <tr>
        <td align=center colspan="5">No Class (Labor Day)</td>
      </tr>
      <tr>
        <td>Wed, Sept. 4 </td>
        <td class="topic">
            Lecture 4: Neural Network
          <div class="subtopic">
              Binary Classification / Multi-Class Classification </br>
              Sigmoid / Softmax </br>
              Cross-Entropy Loss
          </div>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/2098vkbyph1qlmo6upe7s/L4_Neural-Network.pdf?rlkey=ikfsp40qn44ucoiy6eg8a8lyq&st=8qho79l5&dl=0" target="_blank">[Slides]</a></li>
            <li><a href="https://d2l.ai/chapter_linear-classification/softmax-regression.html" target="_blank">[D2L Sec 4.1] </a> </li>
            <li><a href="https://www.youtube.com/watch?v=ErfnhcEV1O8&themeRefresh=1" target="_blank">[A short intro to Entropy, Cross-Entropy and KL Divergence] </a> </li>
            <li><a href="https://cs231n.github.io/classification/" target="_blank">[231n Image Classification]</a></li>
            <li><a href="https://cs231n.github.io/linear-classify/" target="_blank">[231n Linear Classification]</a></li>
            
          </ul>
        </td>
        <td>
          <em>Assignment 1 due</em>
                    Assignment 2 out
                    <li><a href="https://www.dropbox.com/scl/fi/0j3nlt3llwifs7344u03j/lab2a_gradient_descent.ipynb?rlkey=8miyfcysramj8dju9lhydhw8s&st=miga5u3x&dl=0" target="_blank">[Lab2a: Gradient Descent]</a> </li>
                    <li><a href="https://www.dropbox.com/scl/fi/50x3eo95d0i9y762z2avv/lab2b_PyTorch.ipynb?rlkey=dh4x09dqxit2g64uv581i7mxb&st=n41u6e5m&dl=0" target="_blank">[Lab2b: Pytorch Basics]</a> </li>
                    <li><a href="https://www.dropbox.com/scl/fi/gm6rdcx7uzbbtdg2wjv17/lab2c_linear_classifier.ipynb?rlkey=tkdmpwh9rorrkpovxwerv1oxl&st=iy00lvaf&dl=0" target="_blank">[Lab2c: Linear Classifier]</a> </li>
                  
        </td>
      </tr>

<!--       <tr class="gray">
        <td>Fri, Jan. 26 </td>
        <td class="topic2"><a href="https://www.dropbox.com/s/yrh7cv2fazy7kzz/lab1-linear-algrebra.pdf?dl=0">Lab 1: Numpy Basics</a>
          <div class="subtopic">
          </div>
        </td>
        <td>
            <i>Maths review: linear algebra</i>
          <ul class="materials">
            <li><a href="https://www.deeplearningbook.org/contents/linear_algebra.html">Goodfellow Chapter 2</li>
            <li><a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of linear algebra</li>
          </ul>
        </td>
        <td>
        </td>
      </tr> -->

      <tr class="gray">
        <td>Fri, Sept. 6 </td>
        <td class="topic">
            Lecture 5: Multi-Layer Perceptron (MLP)
          <div class="subtopic">
              Linear Problems / Non-Linear Problems </br>
              Feature transforms
              Model: Fully-connected networks </br>
              Computational Graph </br>
              Optimization: Backpropagation </br>
<!--               Algebraic / Visual / Geometric viewpoints </br>
              Softmax / SVM classifiers -->
          </div>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/caepf4mselyxaugxxj1l6/L5_Multi-Layer-Perceptron.pdf?rlkey=7cu54umc2rjfkph5pswt1md5x&st=ssaej747&dl=0" target="_blank">[Slides]</a></li>
            <li><a href="https://playground.tensorflow.org/" target="_blank">[MLP web training]</a></li>
            <li><a href="https://cs231n.github.io/classification/" target="_blank">[231n Image Classification]</a></li>

            
          </ul>
        </td>
        <td>
<!--           <strike><font color=#800000>lab0 due</font></strike>
            <br/>ps1 out (dip) -->
        </td>
      </tr>

      <tr class="gray">
        <td>Mon, Sept. 9</td>
        <td class="topic">
            Lecture 6: Activation Functions and Optimization
          <div class="subtopic">
            Activation Functions: ReLU, Sigmoid, tanh, Leaky ReLU, ELU </br>
            Regularization  </br>
            Weight decay </br>
 <!--            Lecture 5: Regularization + Optimization
            <div class="subtopic">
            Regularization  </br>
            Weight decay </br>
            Stochastic Gradient Descent </br>
            Momentum, AdaGrad, Adam </br>
            Second-order optimizers </br> -->
          </div>
        </td>
        <td>
            <!-- <i>Maths review: linear algebra</i> -->
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/fy9o96kiog45sjyrosbs7/L6_Activation-Functions.pdf?rlkey=96g81qlns8rdjz5dxs063tpxg&st=zr9kjzfk&dl=0">[Slides]</a></li>
            <li><a href="https://playground.tensorflow.org/" target="_blank">[MLP web training]</a></li>
            <li><a href="https://cs231n.github.io/classification/" target="_blank">[231n Image Classification]</a></li>
<!--             <li><a href="https://cs231n.github.io/optimization-1/">[231n Optimization]</a></li>
            <li><a href="https://www.deeplearningbook.org/contents/optimization.html">[DL Sec. 8.1 to 8.6]</a></li> -->
          </ul>
        </td>
        <td>

        </td>
        <!---
        <td> 
          Assignment 1 due (Jan. 30)
        </td> --->

      </tr>

      <tr>
        <!-- <td rowspan=12 style="vertical-align:middle;text-align:center;" bgcolor="#FFBFBF">Deep Learning Architectures<br/></td> -->
        <td rowspan=12 style="vertical-align:middle;text-align:center;">Deep Learning Architectures<br/></td>
        <td>Wed, Sept. 11</td>
        <td class="topic">
            Lecture 7: Convolutional Neural Networks (CNNs)
            <div class="subtopic">
          <!--   Softmax </br>
            Layer: activation linear -->

            <!-- Neural Networks </br> -->
            Weight initialization, dropout, haperparameters </br>
            Universal approximation theorem </br>
            Intro to CNNs -- Convolution </br>
          </div>
        </td>
        <td>
            <!-- <i>Task I: Region of Interest (ROI) Detection</i> -->
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/z8d9zlp922nsimpjhg3ed/L7_CNN.pdf?rlkey=ztqn35m4a0nvj3h23m5162qoe&st=0ofnos8c&dl=0">[Slides]</a></li>
            <li><a href="https://www.deeplearningbook.org/contents/regularization.html">[DL Sec. 7.1]</a>, <a href="https://d2l.ai/chapter_builders-guide/init-param.html">[D2L Sec. 6.3]</a></li>
            <li><a href="https://www.deeplearningbook.org/contents/convnets.html">[DL Sec. 9.1, 9.2]</a>, <a href="https://d2l.ai/chapter_convolutional-neural-networks/why-conv.html">[D2L Sec. 7.1]</a>, <a href="https://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html">[D2L Sec. 7.2]</a></li>
          </ul>
        </td>

        <td>
          <em>Assignment 2 due</em>
        </td>

      </tr>

      <tr>
        <td>Fri, Sept. 13</td>
        <td class="topic">
            Lecture 8: Convolutional Neural Networks (CNNs)
            <div class="subtopic">
            Convolution: kernel, receptive field, stride </br>
            Padding </br>
            Learning convolutional filters </br>
            One layer (breadth): multiple kernels </br>
            K layers (depth): nonlinearity in between </br>
          </div>

            
        </td>
        <td>
            <!-- <i>Task II: Image Preprocessing</i> -->
          <ul class="materials">
              <li><a href="https://www.dropbox.com/scl/fi/alio14tllfta0n1h6ipat/L8_CNN-2.pdf?rlkey=kdfx2gnp7dxeuebxpdleewhye&st=et14thp1&dl=0" target="_blank">[Slides]</a></li>
              <li><a href="https://setosa.io/ev/image-kernels/" target="_blank">[Image Kernels]</a></li>
              <li><a href="https://www.deeplearningbook.org/contents/convnets.html" target="_blank">[DL Sec. 9.3, 9.4]</a>, <a href="https://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html" target="_blank">[D2L Sec. 7.2]</a>, <a href="https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html" target="_blank">[D2L Sec. 7.3]</a>, <a href="https://d2l.ai/chapter_convolutional-neural-networks/channels.html" target="_blank">[D2L Sec. 7.4]</a>, <a href="https://d2l.ai/chapter_convolutional-neural-networks/pooling.html" target="_blank">[D2L Sec. 7.5]</a></li>

              
          </ul>
        </td>

        <td>
            <!-- <strike><font color=#800000>lab1 due</font></strike> -->
        </td>
      </tr>


      <tr>
        <td>Mon, Sept. 16</td>
        <td class="topic">
            Lecture 8: Convolutional Neural Networks (CNNs) -- Continued    
        </td>
        <td>
            <!-- <i>Task II: Image Preprocessing</i> -->
          <ul class="materials">
              <li><a href="https://www.dropbox.com/scl/fi/alio14tllfta0n1h6ipat/L8_CNN-2.pdf?rlkey=kdfx2gnp7dxeuebxpdleewhye&st=et14thp1&dl=0" target="_blank">[Slides]</a></li>
              <li><a href="https://setosa.io/ev/image-kernels/" target="_blank">[Image Kernels]</a></li>
              <li><a href="https://www.deeplearningbook.org/contents/convnets.html" target="_blank">[DL Sec. 9.3, 9.4]</a>, <a href="https://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html" target="_blank">[D2L Sec. 7.2]</a>, <a href="https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html" target="_blank">[D2L Sec. 7.3]</a>, <a href="https://d2l.ai/chapter_convolutional-neural-networks/channels.html" target="_blank">[D2L Sec. 7.4]</a>, <a href="https://d2l.ai/chapter_convolutional-neural-networks/pooling.html" target="_blank">[D2L Sec. 7.5]</a></li>

              
          </ul>
        </td>

        <td>
            <!-- <strike><font color=#800000>lab1 due</font></strike> -->
        </td>
      </tr>



      <tr class="gray">
        <td>Wed, Sept. 18</td>
        <td class="topic">
          Lecture 9: CNNs
          <div class="subtopic">
            Pooling </br>
            AlexNet </br>
            Batch Normalization </br>
            ResNet + Residual Blocks </br>
          </div>
        </td>
        <td>
            <i></i>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/3u2kg6eydm6jisjnc8agc/L9_CNN-3.pdf?rlkey=zgd99y98kjv98ws3vjetywcpl&st=cs2jfxc8&dl=0" target="_blank">[Slides]</a></li>
            <li><a href="https://d2l.ai/chapter_convolutional-neural-networks/pooling.html" target="_blank">[D2L Sec. 7.5]</a>, <a href="https://d2l.ai/chapter_convolutional-neural-networks/lenet.html" target="_blank">[D2L Sec. 7.6]</a></li>
            <li><a href="https://d2l.ai/chapter_convolutional-modern/alexnet.html" target="_blank">[D2L Sec. 8.1]</a>, <a href="https://d2l.ai/chapter_convolutional-modern/vgg.html" target="_blank">[D2L Sec. 8.2]</a>, <a href="https://d2l.ai/chapter_convolutional-modern/nin.html" target="_blank">[D2L Sec. 8.3]</a>, <a href="https://d2l.ai/chapter_convolutional-modern/googlenet.html" target="_blank">[D2L Sec. 8.4]</a>, <a href="https://d2l.ai/chapter_convolutional-modern/batch-norm.html" target="_blank">[D2L Sec. 8.5]</a>, <a href="https://d2l.ai/chapter_convolutional-modern/resnet.html" target="_blank">[D2L Sec. 8.6]</a></li>
          </ul>
        </td>
        <td>
          Assignment 3 out 
          <li><a href="https://www.dropbox.com/home/2024Fall/Assignments">[Lab 3: Autograd and NN]</a></li>
        </td>
      </tr>

      <tr class="gray">
        <td>Fri, Sept. 20</td>
        <td class="topic">
          Lecture 10: CNN Architectures
          <div class="subtopic">
            AlexNet, VGGNet, GoogLeNet, BatchNorm, ResNet </br>
            Deep Learning Framework </br>
          </div>
        </td>
        <td>
            <i></i>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/ume58xc345sm3gn5mev17/L10_CNN-architectures.pdf?rlkey=hie028ztiv8e5nqnlmfnivw02&st=lqk0cper&dl=0" target="_blank">[Slides]</a></li>
            <li><a href="http://cs231n.stanford.edu/slides/2023/lecture_6.pdf" target="_blank">[CS231n CNN Architectures]</a></li>
            <li><a href="https://d2l.ai/chapter_convolutional-modern/alexnet.html" target="_blank">[D2L Sec. 8.1]</a>, <a href="https://d2l.ai/chapter_convolutional-modern/vgg.html" target="_blank">[D2L Sec. 8.2]</a>, <a href="https://d2l.ai/chapter_convolutional-modern/nin.html" target="_blank">[D2L Sec. 8.3]</a>, <a href="https://d2l.ai/chapter_convolutional-modern/googlenet.html" target="_blank">[D2L Sec. 8.4]</a>, <a href="https://d2l.ai/chapter_convolutional-modern/batch-norm.html" target="_blank">[D2L Sec. 8.5]</a>, <a href="https://d2l.ai/chapter_convolutional-modern/resnet.html" target="_blank">[D2L Sec. 8.6]</a></li>
          </ul>
        </td>
        <td></td>
      </tr>

      <tr>
        <td>Mon, Sept. 23</td>
        <td class="topic">
            Lecture 11: Training Neural Networks

          <div class="subtopic">
              Activation functions </br>
              Data preprocessing </br>
              Weight initialization </br>
              Data augmentation </br>
              Regularization (Dropout, etc) </br>
              Learning rate schedules </br>
              Hyperparameter optimization </br>
              Transfer learning </br>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/7zzjkx6ggro064zisn8ku/L11_Training-Neural-Networks.pdf?rlkey=gd3n8ihs3fm53zpduut3fxsry&st=nkolc2xj&dl=0" target="_blank">[Slides]</a></li>
            <li><a href="https://cs231n.github.io/neural-networks-2/" target="_blank">[CS231n Traning I]</a></li>
            <li><a href="https://karpathy.github.io/2019/04/25/recipe/" target="_blank">[Karpathy "Recipe for Training"]</a></li>
            
          </ul>
        </td>
        <td>
        </td>
      </tr>


      <tr>
        <td>Wed, Sept. 25</td>
        <td class="topic">
          Lecture 12: Deep Learning Framework
          <div class="subtopic">
              PyTorch </br>
              Dynamic vs Static graphs </br>
        </td>
        <td>  
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/t4dn075clpord99bdkcac/L12_PyTorch.pdf?rlkey=5qo98arn57jc7ztr8tbfqi690&st=9rlb0uog&dl=0" target="_blank">[Slides]</a></li>
            <li><a href="https://www.dropbox.com/scl/fi/0d02kcboz8kq9m3ynepth/9_hackers_guide.pdf?rlkey=cryutcyvjanbl29mvubyaz0uz&e=1&dl=0" target="_blank">[Hacker’s guide to DL]</a></li>
              
          </ul>
        </td>

        <td>
            <i>Assignment 3 Due</i>
        </td>

    </tr>

      <tr class="gray">
        <td>Fri, Sept. 27</td>
        <td class="topic">
          Lecture 12: PyTorch Review Session (continued)
          <div class="subtopic">
              PyTorch </br>
              Dynamic vs Static graphs </br>
          </div>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/t4dn075clpord99bdkcac/L12_PyTorch.pdf?rlkey=5qo98arn57jc7ztr8tbfqi690&st=9rlb0uog&dl=0" target="_blank">[Slides]</a></li>
            <li><a href="https://www.dropbox.com/scl/fi/0d02kcboz8kq9m3ynepth/9_hackers_guide.pdf?rlkey=cryutcyvjanbl29mvubyaz0uz&e=1&dl=0" target="_blank">[Hacker’s guide to DL]</a></li>
              
          </ul>
        </td>
        <td>
          
        </td>
      </tr>
       
      </tr>



      <tr class="gray">
        <td>Mon, Sept. 30</td>
        <td class="topic">
          Lecture 13: Final Project Overview
          <div class="subtopic">
          Final Project Overview </br>
          Life cycle of a Machine Learning System </br>
          Sequential models use cases </br>
          </div>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/ffiql6i31zbsxpw79i7m5/L13_Final-Project-Overview.pdf?rlkey=7kxxuy6pkv0or2fakp17u8c43&st=u6xnoest&dl=0" target="_blank">[Slides]</a></li>
          </ul>
        </td>
        <td>

        </td>
      </tr>


      <tr class="gray">
        <td>Wed, Oct. 2</td>
        <td class="topic">
          Lecture 14: Recurrent Neural Networks (RNNs)
          <div class="subtopic">
          Sequential models use cases </br>
          CNNs for sequences </br>
          RNNs </br>
          </div>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/kluhu5xwbbq68bk02qvyt/L14_RNN.pdf?rlkey=nvvyk3tsq35qhuahp58cmca6t&st=7tqgn908&dl=0" target="_blank">[Slides]</a></li>
            <li><a href="https://www.dropbox.com/scl/fi/huhp63uo0io242vihhx0f/rnns.pdf?rlkey=1r99da935tdwz1s67pxle6pdg&e=1&dl=0" target="_blank">[RNNs]</a></li>
            
          </ul>
        </td>
        <td>

        </td>
      </tr>


      <tr>
        <td>Fri, Oct. 4</td>
        <td class="topic">
        Lecture 15: Recurrent Networks: Stability analysis and LSTMs  
         <div class="subtopic">
        Gradient Explosion </br>
        LSTM, GRU </br>
        Language modeling </br>
        </td>
        <td>
            <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/rqjkwt7p4xlvcm7vis9js/L15_LSTM.pdf?rlkey=vdrwkmlgde1kzauk821fxgfx1&st=v19nxmkj&dl=0" target="_blank">[Slides]</a></li>
            <li><a href="https://www.dropbox.com/scl/fi/huhp63uo0io242vihhx0f/rnns.pdf?rlkey=1r99da935tdwz1s67pxle6pdg&e=1&dl=0" target="_blank">[RNNs]</a></li>
            <li><a href="https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Spring.2019/archive-f19/www-bak11-22-2019/document/lecture/lec13.recurrent2.pdf" target="_blank">[RNN Stability analysis and LSTMs]</a></li>
            
          </ul>

        </td>
        <td>

        </td>

      </tr>


      <tr>
        <td>Mon, Oct. 7</td>
        <td class="topic">
          Lecture 15: Recurrent Networks: Stability analysis and LSTMs (2)     
        </td>
        <td>
          <ul class="materials">
          <li><a href="https://www.dropbox.com/scl/fi/rqjkwt7p4xlvcm7vis9js/L15_LSTM.pdf?rlkey=vdrwkmlgde1kzauk821fxgfx1&st=v19nxmkj&dl=0" target="_blank">[Slides]</a></li>
        </td>

        <td>
        </td>
      </tr>


      <tr>
          <td align=center colspan="5"><h3><font color=#800000> Module II: Advanced Topics on Deep Learning</font></h3></td>
      </tr>
      <tr>
        <td rowspan=6 style="vertical-align:middle;text-align:center;">Vision Applications<br/></td>
        <td>Wed, Oct. 9</td>
        <td class="topic">
          Lecture 16: Attention and Transformers
          <div class="subtopic">
            Self-Attention </br>
            Transformers </br>
              </div>
        </td>
        <td>
          <ul class="materials">
              <li><a href="https://www.dropbox.com/scl/fi/mj5x7g9mfmc2q7jqf2cdz/L16_Attention-and-Transformers.pdf?rlkey=kqyuq8tw1bvgukdv14xmngdeo&st=r5gj2xzm&dl=0" target="_blank">[Slides]</a></li>
              <li><a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank">[Attention is all you need]</a></li>
              <li><a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank">[BERT Paper]</a></li>
              <li><a href="http://jalammar.github.io/illustrated-transformer/" target="_blank">[The Illustrated Transformer]</a></li>
              <li><a href="https://arxiv.org/pdf/2207.09238.pdf" target="_blank">[Formal Algorithms for Transformers]</a></li>
          </ul>

        </td>
        <td>
          Assignment 4 Part 1 Out
          <ul>
            <li><a href="https://www.dropbox.com/scl/fi/9t6iqyu9ygl5dfgkia2pt/lab4_neural_machine_translation.ipynb?rlkey=umy89kkfgexkxkcfmtgql15lp&st=k3m8e8b2&dl=0">[Lab 4: Neural Machine Translation]</a>
            </li>
          </ul>
          </td>
      </tr>


      <tr>
        <td>Fri, Oct. 11</td>
        <td class="topic">
          Lecture 16: Attention and Transformers (2)
          <div class="subtopic">
          Multi-head Self-Attention </br>
          Mask Self-Attention </br>
          </div>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/mj5x7g9mfmc2q7jqf2cdz/L16_Attention-and-Transformers.pdf?rlkey=kqyuq8tw1bvgukdv14xmngdeo&st=r5gj2xzm&dl=0" target="_blank">[Slides]</a></li>
 
          </ul>
        </td>
        <td>

        </td>
      </tr>


      <tr>
        <td align=center colspan="4">No Class (Fall Break)</td>
      </tr>

<!--       <tr>
          <td align=center colspan="5"><h3><font color=#800000> Module II: Advanced Topics on Deep Learning</font></h3></td>
      </tr> -->
      <tr>
        <!-- <td rowspan=6 style="vertical-align:middle;text-align:center;">Vision Applications<br/></td> -->
        <td>Wed, Oct. 16</td>
        <td class="topic">
            Lecture 17: BERT and GPTs
          <div class="subtopic">
          Encoder-Decoder Attention </br>
          Word Embedding </br>
          Pre-training </br>
            </div>
        </td>
        <td>
          <ul class="materials">
          <li><a href="https://www.dropbox.com/scl/fi/tgpzr2he68ckkwpmzsdz0/L17_Transformer-and-BERT.pdf?rlkey=lad0rkmnmwky23gax603gpllz&st=7spntg7d&dl=0" target="_blank">[Slides]</a></li>
        </ul>
        </td>
        <td>
        </td>
      </tr>


      <tr>
        <td>Fri, Oct. 18</td>
        <td class="topic">
          Lecture 17: BERT and GPTs (2)
            <div class="subtopic">
            </div>
        </td>
        <td>
          <ul class="materials">
          <li><a href="https://www.dropbox.com/scl/fi/tgpzr2he68ckkwpmzsdz0/L17_Transformer-and-BERT.pdf?rlkey=lad0rkmnmwky23gax603gpllz&st=7spntg7d&dl=0" target="_blank">[Slides]</a></li>
        </td>

        <td>
            Assignment 4 Part 1 Due
        </td>
      </tr>


 
      <tr>
        <td>Mon, Oct. 21</td>
       <td class="topic">
            Lecture 18: Training Large Language Models

            <div class="subtopic">
            Self-Supervised Learning </br>
            Data Scaling </br>
          </div>
        </td>

        <td>
          <ul class="materials">
                  <li><a href="https://www.dropbox.com/scl/fi/f2h09myrgrnnaistrrl04/L18_Training-LLM.pdf?rlkey=em5ovfui4z847f653x42m91pp&st=g81r87w1&dl=0" target="_blank">[Slides]</a></li>

                  <li><a href="https://github.com/Mooler0410/LLMsPracticalGuide?tab=readme-ov-file" target="_blank">[The Practical Guides for Large Language Models]</a></li>
         
        </td>
        <td>
          Assignment 4 Part 2 out (Transformers)
        </td>
      </tr>


      <tr>
        <td rowspan=11 style="vertical-align:middle;text-align:center;">Generative and Interactive Visual Intelligence<br/></td>
        <td>Wed, Oct. 23</td>
       <td class="topic">
            Lecture 19: Computer Vision: Detection and Segmentation
          <div class="subtopic">
            Semantic segmentation </br>
          Object detection </br>
        Instance segmentation </br>
          </div>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/sym5iscjzf069sch7xgdj/Lecture-21.pdf?rlkey=tpp5g6nta5ftmjvbnjjd8qfyp&dl=0" target="_blank">[Slides]</a></li>
        </td>
        <td>
            
        </td>
      </tr>


      <tr>
        <td>Fri, Oct. 25</td>
       <td class="topic">
            Lecture 19: Computer Vision: Detection and Segmentation (2)
          <div class="subtopic">
          </div>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/sym5iscjzf069sch7xgdj/Lecture-21.pdf?rlkey=tpp5g6nta5ftmjvbnjjd8qfyp&dl=0" target="_blank">[Slides]</a></li>
        </td>
        <td>
            
        </td>
      </tr>


      <tr>
        <td>Mon, Oct. 28</td>
       <td class="topic">
        Lecture 20: Generative Models (1)
          <div class="subtopic">
          Unsupervised Learning </br>
          Clustering / PCA </br>
          Autoregressive Models </br>
          </div>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/wra91g5ansniwi0z4567u/L20_Generative-Models_Autoregressive-Models.pdf?rlkey=m5w8oqapgugw8dyek2ngn7iko&st=fg5rry3d&dl=0" target="_blank">[Slides]</a></li>
        </td>
        <td>
            
        </td>
      </tr>

      

      <tr>
        <td>Wed, Oct. 30</td>
        <td class="topic">
          Lecture 21: Generative Models (2) -- VAEs
          <div class="subtopic">
              Convolutional AEs, Transpose Convolution</br>
              Variational Autoencoders (VAE) </br>
        </td>
        <td>
          <ul class="materials">
            <li><a href="https://www.dropbox.com/scl/fi/4w8hafkggcm1tznl5jrgx/L21_Generative-Models_VAEs.pdf?rlkey=jlrlgnpv683wh1s418lbds4q1&st=e2ju83po&dl=0" target="_blank">[Slides]</a></li>
            <li><a href="https://www.dropbox.com/scl/fi/i6bd17t4u206xjxrca4hh/Convolutional-Autoencoder.pdf?rlkey=2algqs95hxvqml8ypx1vo1ium&dl=0" target="_blank">[Reading: Convolutional AEs]</a></li>
        </td>
        <td>
          
        </td>
    </tr>


    <tr>
        <td>Fri, Nov. 1</td>
        <td class="topic">
        Lecture 24: Generative Models (2) -- VAEs (continued)
          <div class="subtopic">
              VAE Loss - KL Divergence </br>
              Reparameterization trick </br>
              Conditional VAE </br>
          </div>
        </td>
        <td>
          <ul class="materials">
          <li><a href="https://www.dropbox.com/scl/fi/3abe91x130wcrv2eu1594/Lecture-24.pdf?rlkey=mwmih29kyros5skueqwsiwd2k&dl=0" target="_blank">[Slides]</a></li>
          <li><a href="https://www.youtube.com/watch?v=9_eZHt2qJs4" target="_blank">[KL Divergence]</a></li>
        </td>
        <td>
          Assignment 4 Part 2 Due (11/2)
        </td>
      </tr>


      <tr>
        <td>Mon, Nov. 4</td>
        <td class="topic">
        Lecture 22: Generative Models (3) -- GANs
          <div class="subtopic">
              Generative Adversarial Networks (GANs) </br>
              Training GANs and challenges </br>
              Applications </br>
          </div>
        </td>
        <td>
          <ul class="materials">
          <li><a href="https://www.dropbox.com/scl/fi/hv2hmg05cbs9pdlzydoer/L22_Generative-Models_GANs.pdf?rlkey=0pwuvkmjcq59bbuoimt84k0kn&st=sht3angj&dl=0" target="_blank">[Slides]</a></li>
        </td>
        <td>
        </td>
      </tr>


      <tr>
        <td>Wed, Nov. 6</td>
        <td class="topic">
        Lecture 23: Generative Models (4) -- Diffusion Models
          <div class="subtopic">
              Denoising Diffusion Probabilistic Models (DDPMs) </br>
              Conditional Diffusion Models </br>
          </div>
        </td>
        <td>
          <ul class="materials">
          <li><a href="https://www.dropbox.com/scl/fi/8wtz4va6sotk2p6uffijx/L23_Generative-Models_Diffusion-Models.pdf?rlkey=64hudv0v3f759fvxkvxzywpya&st=h1bdunwb&dl=0" target="_blank">[Slides]</a></li>
        </td>
        <td></td>
      </tr>


      <tr>
        <td>Fri, Nov. 8</td>
        <td class="topic">
            Lecture 23: Generative Models (4) -- Diffusion Models (continued)
          <div class="subtopic">
              Denoising Diffusion Probabilistic Models (DDPMs) </br>
              Conditional Diffusion Models </br>
           </div>
        </td>
        <td>
          <ul class="materials">
          <li><a href="https://www.dropbox.com/scl/fi/8wtz4va6sotk2p6uffijx/L23_Generative-Models_Diffusion-Models.pdf?rlkey=64hudv0v3f759fvxkvxzywpya&st=h1bdunwb&dl=0" target="_blank">[Slides]</a></li>
        </td>
        <td>
        </td>
      </tr>


<!--       <tr>
        <td align=center colspan="5">No Class (Good Friday)</td>
      </tr>
      <tr>
        <td align=center colspan="5">No Class (Easter Monday)</td>
      </tr> -->


      <tr>
        <td>Mon, Nov. 11</td>
        <td class="topic">
          Lecture 24: Self-supervised Learning
          <div class="subtopic">
              Pretext tasks </br>
              Contrastive representation learning </br>
              Instance contrastive learning: SimCLR and MOCO </br>
              Sequence contrastive learning: CPC </br>
            <br/></div>
        </td>
        <td>
          <ul class="materials">
          <li><a href="https://www.dropbox.com/scl/fi/9y1us5ddo26zkw7nls8es/L24_SSL.pdf?rlkey=6z0x2fs5170jb4wnhh6yax7fr&st=bcs9oh3s&dl=0" target="_blank">[Slides]</a></li>
        </td>

        <td>
        </td>
      </tr>
      


      <tr>
        <td>Wed, Nov. 13</td>
        <td class="topic">
            Lecture 24: Self-supervised learning (continued)
          <div class="subtopic">
            </div>
        </td>
        <td>
          <ul class="materials">
          <li><a href="https://www.dropbox.com/scl/fi/9y1us5ddo26zkw7nls8es/L24_SSL.pdf?rlkey=6z0x2fs5170jb4wnhh6yax7fr&st=bcs9oh3s&dl=0" target="_blank">[Slides]</a></li>
          <li><a href="https://arxiv.org/pdf/2002.05709.pdf" target="_blank">[SimCLR]</a></li>
          <li><a href="https://arxiv.org/pdf/1911.05722.pdf" target="_blank">[MoCo]</a></li>
          <li><a href="https://arxiv.org/pdf/2003.04297.pdf" target="_blank">[MoCo v2]</a></li>
          <li><a href="https://arxiv.org/pdf/1807.03748.pdf" target="_blank">[CPC]</a></li>
          
          </ul>
        </td>

        <td> 
        </td>
      </tr>



      <tr>
        <td>Fri, Nov. 15</td>
        <td class="topic">
            Lecture 25: Transfer Learning
            <div class="subtopic">
              Finetuning </br>
              Knowledge distillation </br>
              Fundation Models: Text Prompting, Visual Prompting, Prompting for other modalities, Combining Foundation Models </br>
            <br/></div>
        </td>
        <td>
          <ul class="materials">
          <li><a href="https://www.dropbox.com/scl/fi/cymuo702gywcpegv4jjja/L25_Transfer-Learning.pdf?rlkey=j65n4eztkfqoo13sd10zoe9tf&st=zav26k5n&dl=0" target="_blank">[Slides]</a></li>
          <li><a href="https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/examples/chain_of_thought_react.ipynb" target="_blank">[Chain of Thought]</a></li>
          <li><a href="https://thegradient.pub/prompting/" target="_blank">[Prompting]</a></li>
          <li><a href="https://www.youtube.com/watch?v=FE88OOUBonQ" target="_blank">[Visual Prompting]</a></li>
          <li><a href="https://www.youtube.com/watch?v=DhRoTONcyZE" target="_blank">[LoRA]</a></li>
          
          </ul>
        </td>

        <td> 
        </td>
      </tr>


      


<!--       <tr class="gray">
        <td>Fri, Nov. 8 <br/></td>
        <td class="topic">
          <span style="color: #33A6B8;">LLaVA: A Vision-and-Language Approach to Computer Vision in the Wild</span>
          <div class="subtopic">
              Guest Speaker: <a href="https://chunyuan.li/" target="_blank">Chunyuan Li</a> (Microsoft Research) <br>
          </div>
        </td>
        <td>
          <p style="font-size: 12px;">Abstract: The future of AI is in creating systems like foundation models that are pre-trained once, and will handle countless many downstream tasks directly (zero-shot), or adapt to new tasks quickly (few-shot). In this talk, I will discuss our vision-language approach to achieving “Computer Vision in the Wild (CVinW)”:  building such a transferable system in computer vision (CV) that can effortlessly generalize to a wide range of visual recognition tasks in the wild. I will first describe the definition and current status of CVinW, and briefly summarize our efforts on benchmark and modeling. I will dive into Large Language-and-Vision Assistant (LLaVA) and its series, including LLaVA-Med, LLaVA-1.5,  LLaVA-NeXT, LLaVA-Interactive, LLaVA-Plus.  LLaVA family represents the first open-source project to exhibit the GPT-4V level capabilities in image understanding and reasoning. demonstrate a promising path to build customizable large multimodal models that follow humans' intent with an affordable cost.</p>

          <p style="font-size: 15px;">Reference Papers: <a href="https://llava-vl.github.io/" target="_blank">[LLaVA]</a>, <a href="https://github.com/microsoft/LLaVA-Med" target="_blank">[LLaVA-Med]</a>, <a href="https://arxiv.org/pdf/2310.03744.pdf" target="_blank">[LLaVA-1.5]</a>, <a href="https://llava-vl.github.io/blog/2024-01-30-llava-next/" target="_blank">[LLaVA-NeXT]</a>, <a href="https://llava-vl.github.io/llava-interactive/" target="_blank">[LLaVA-Interactive]</a>, <a href="https://llava-vl.github.io/llava-plus/" target="_blank">[LLaVA-Plus]</a>.</p>
 
        </td>
        <td> </td>
      </tr> -->


<!--       <tr>
        <td>Mon, Nov. 11 <br/></td>
        <td class="topic">
          <span style="color: #33A6B8;">Learning to and from Predict in Computer Vision</span>

          <div class="subtopic">
                      Guest Speaker: <a href="https://www.tianhongli.me/" target="_blank">Tianhong Li</a> (MIT CSAIL) </br>
          </div>
        </td>
        <td>
          <p style="font-size: 12px;">Abstract: Predictive learning has been a long-standing topic in computer vision and has gain increased attention recently due to the success of large language models. This lecture will introduce several pivotal studies within this domain. We begin with image inpainting — a technique vital for understanding context and filling missing information. We will then see how predictive learning could facilitate unsupervised representation learning. Finally, we will introduce how can we use predictive learning to generate novel images.</p></br>

          <p style="font-size: 15px;">Reference Papers: <a href="https://compvis.github.io/taming-transformers/" target="_blank">[VQGAN]</a>, <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.pdf" target="_blank">[MAE]</a>, <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Li_MAGE_MAsked_Generative_Encoder_To_Unify_Representation_Learning_and_Image_CVPR_2023_paper.pdf" target="_blank">[MAGE]</a>.</p>

        </td>
        <td>
            
        </td>
      </tr> -->


<!--       <tr>
        <td>Wed, Nov. 13 </td>
        <td class="topic">
          <span style="color: #33A6B8;">Foundation Priors for Robot Perception: From Neural Radiance Fields to OpenAI Sora</span>

          <div class="subtopic">
                Guest Speaker: <a href="https://www.episodeyang.com/" target="_blank">Ge Yang</a> (MIT CSAIL)
          </div>
        </td>
        <td>
          <p style="font-size: 12px;">Abstract: Recent developments in Artificial Intelligence have produced a trifecta of new techniques in generative modeling, computer graphics, and representation learning that once combined, will lead to radical changes in robotics. In this talk, we will study robot perception as an ill-defined inverse problem whose goal is to infer knowledge of the environment from noise and partial observability. We will start with Neural Radiance Fields (NeRFs) and study ways to combine them with prior knowledge from Foundation Models that are trained over internet-scale datasets to give robots the ability to know what is where in their surrounding environment. We will then look at the AI debate over priors vs data, and discuss how it is affected by recent results from OpenAI sora, the state-of-the-art AI system for generating videos from text.</p></br>

          <p style="font-size: 15px;">Reference Papers: <a href="https://openai.com/research/clip" target="_blank">[CLIP]</a>, <a href="https://www.matthewtancik.com/nerf" target="_blank">[NeRF]</a>, <a href="https://f3rm.github.io/" target="_blank">[Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation (CoRL 2023 Best Paper)]</a>.</p>

        </td>

        <td> 
        </td>
      </tr> -->



<!--       <tr>
        <td rowspan=5 style="vertical-align:middle;text-align:center;">AI for Science<br/></td>
        <td>Fri, Nov. 15</td>
        <td class="topic">
          <span style="color: #33A6B8;">Towards Efficient and High-Quality 3D Generation</span>
            
          <div class="subtopic">
            Guest Speaker: <a href="https://vivianszf.github.io/" target="_blank">Zifan Shi</a> (Stanford / HKUST)<br>
            
          </div>
        </td>
        <td>
          <p style="font-size: 12px;">Abstract: 3D generation has received growing attention due to its potential in modeling the 3D visual world. Despite remarkable advancements, there remains a significant journey ahead. In this talk, we will explore three key aspects of 3D generation. Firstly, we will focus on geometry quality, delving into the design of the discriminator. This crucial component has often been overlooked in many existing 3D generative approaches. Secondly, we will examine the realm of animatable human generation, probing into techniques and challenges associated with this dynamic aspect of 3D modeling. Lastly, we will discuss strategies for constructing a foundational model tailored for 3D generation, aiming to provide a robust framework for further advancements in the field. </p></br>

          <p style="font-size: 15px;">Reference Papers: <br>
            <a href="https://vivianszf.github.io/geod/" target="_blank">[Improving 3D-aware Image Synthesis with A Geometry-aware Discriminator]</a>,<br> 
            <a href="https://vivianszf.github.io/pof3d/" target="_blank">[Learning 3D-aware Image Synthesis with Unknown Pose Distribution]</a>,<br> 
            <a href="https://rameenabdal.github.io/GaussianShellMaps/" target="_blank">[Gaussian Shell Maps for Efficient 3D Human Generation]</a>,<br>
            <a href="https://justimyhxu.github.io/projects/grm/" target="_blank">[GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation]</a>,<br>
            <a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank">[3D Gaussian Splatting for Real-Time Radiance Field Rendering (Siggraph 2023 Best Paper)]</a>.<br></p>

        </td>
        <td>
          
        </td>

      </tr> -->


      <tr>
        <td rowspan=4 style="vertical-align:middle;text-align:center;">Cutting-Edge Research<br/></td>
        <td>Mon, Nov. 18</td>
        <td class="topic">
          <span style="color: #33A6B8;">Multimodal AI</span>
          <div class="subtopic">
            <p>Guest Speaker: <a href="https://pliang279.github.io/" target="_blank">Paul Liang</a> (MIT Media Lab & MIT EECS)<br></p>

            <p style="font-size: 12px;"><b>Bio:</b> Paul Liang is an Assistant Professor at the MIT Media Lab and MIT EECS. His research advances the foundations of multisensory artificial intelligence to enhance the human experience. He is a recipient of the Siebel Scholars Award, Waibel Presidential Fellowship, Facebook PhD Fellowship, Center for ML and Health Fellowship, Rising Stars in Data Science, and 3 best paper awards. Outside of research, he received the Alan J. Perlis Graduate Student Teaching Award for developing new courses on multimodal machine learning.
          </div>
        </td>
        <td>

          <p style="font-size: 12px;"><b>Abstract:</b> Multimodal AI is a vibrant multi-disciplinary research field that aims to design AI with intelligent capabilities through integrating multiple communicative modalities, including linguistic, acoustic, visual, tactile, and physiological messages. Multimodality brings unique computational and theoretical challenges given the heterogeneity of data sources and the interconnections often found between modalities. By synthesizing a broad range of application domains and theoretical frameworks from both historical and recent perspectives, this lecture is designed to provide an overview of multimodal AI. Building upon a new survey paper (<a href="https://arxiv.org/abs/2209.03430" target="_blank">https://arxiv.org/abs/2209.03430</a>), we will cover three topics: (1) what is multimodal: the principles in learning from heterogeneous, connected, and interacting data, (2) why is it hard: a taxonomy of six core technical challenges faced in multimodal ML but understudied in unimodal ML, and (3) what is next: major directions for future research as identified by our taxonomy.</p>

        </td>

        <td>
            <!-- <font color=#800000>ps4 due</font> -->
        </td>
      </tr>



      <tr>
        <td>Wed, Nov. 20</td>
        <td class="topic">
          <span style="color: #33A6B8;">Towards Test-time Self-supervised Learning (<a href="https://yifeiwang77.com/assets/pdf/TT-SSL-talk-Nov2024.pdf" target="_blank">Slides</a>)</span>
        <div class="subtopic">
            <p>Guest Speaker: <a href="https://yifeiwang77.com/" target="_blank">Yifei Wang</a> (MIT CSAIL) <br></p>

            <p style="font-size: 12px;"><b>Bio:</b> Yifei Wang is a postdoc at MIT CSAIL, advised by Prof. Stefanie Jegelka. He earned his bachelor’s and Ph.D. degrees from Peking University. His research is focused on bridging the theory and practice of self-supervised learning to advance the scalability and safety of foundation models.  His first-author works have been recognized by 3 best paper awards, including the sole Best ML Paper Award at ECML-PKDD 2021, the Silver Best Paper Award at the ICML 2021 AdvML Workshop, and the Best Paper Award at the ICML 2024 ICL Workshop. Academic page: <a href="https://yifeiwang77.com/" target="_blank">https://yifeiwang77.com</a>.
        <td>
          <p style="font-size: 12px;"><b>Abstract:</b> Self-supervised learning (SSL) has been instrumental in unlocking the potential of massive unlabeled datasets, driving the development of foundation models across various domains. However, the benefits from pretraining are diminishing, signaling a plateau in performance gains. To introduce a new dimension for scaling SSL beyond the pretraining stage, we propose the paradigm of test-time self-supervised learning (TT-SSL), which leverages test-time computation to enhance pretrained models without requiring labeled data. We investigate two examples of TT-SSL: (1) unsupervised in-context adaptation, where models adjust to downstream tasks during test time based solely on input context, and (2) self-correction through self-reflection and iterative improvement, allowing models to refine their predictions in real-time without external feedback. This paradigm unlocks the potential of test-time computation for self-exploration and autonomous improvement of model behaviors, offering a promising new direction for advancing the scalability and capabilities of foundation models. </p></br>

        </td>
        <td>
        </td>
      </tr>

      <tr>
        <td>Fri, Nov. 22</td>
        <td class="topic">
          <span style="color: #33A6B8;">Respiratory Intelligence: What Can AI Learn About Your Health from Your Breathing</span>
          <!-- Presentation I -->
          <div class="subtopic">
            <p>Guest Speaker: <a href="https://scholar.google.com/citations?user=v1sUoqwAAAAJ&hl=en" target="_blank">Hao He</a> (MIT CSAIL) <br></p>

            <!-- <b>Zoom Link:</b> <a href="https://mit.zoom.us/j/9470404282?pwd=Wlp4cUFXWWtnaUxXbUpmbmZuS0xndz09&omn=98130504935" target="_blank" style="color: #2EA9DF;"><p style="font-size: 12px;">https://mit.zoom.us/j/9470404282?pwd=Wlp4cUFXWWtnaUxXbUpmbmZuS0xndz09&omn=98130504935</p></a> -->


            <p style="font-size: 12px;"><b>Bio:</b> Hao is a final-year PhD student at MIT, where he is supervised by Prof. Dina Katabi. His research focuses on leveraging machine learning for healthcare applications, with a particular emphasis on sleep science. His contributions have been recognized through publications in top AI conferences and high-impact medical journals. Hao is the recipient of the Takeda Fellowship, awarded to outstanding researchers in AI and health, and Barbara J. Weedon Fellowship, given to researchers making advancements in neurodegenerative diseases.

          </div>
        </td>
        <td>
          <p style="font-size: 12px;"><b>Abstract:</b> Respiration is one of the most fundamental functions of the human body, closely tied to a person’s overall health. In this talk, I will explore how advancements in AI technology allow us to extract valuable health insights from nocturnal breathing patterns. I will address various health aspects, including sleep quality, physiological conditions such as oxygen desaturation and inflammation, and even neurodegenerative diseases like Alzheimer’s. </p></br>
        </td>
        </td>
        <td></td>
      </tr>

      <tr>
        <td>Mon, Nov. 25</td>
        <td class="topic">
          <!-- AI for Healthcare -->
          <span style="color: #33A6B8;">Generalizable Algorithms for Long-Horizon Manipulation in Complex Environments by Integrating Deep Learning and Planning-Based Approaches</span>
          <div class="subtopic">
            <p>Guest Speaker: <a href="https://zt-yang.com/" target="_blank">Zhutian Yang</a> (MIT CSAIL)</p>

            <p style="font-size: 12px;"><b>Bio:</b> Zhutian Yang is a PhD candidate at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL), advised by Leslie Kaelbling and Tomás Lozano-Pérez. Her research focuses on developing algorithms for long-horizon manipulation by combining deep learning with model-based planning techniques. Her work has been published in top robotics and learning conferences such as RSS, CoRL, and ICLR. She has gained valuable experience through internships at NVIDIA’s Seattle Robotics Lab and Toyota Research Institute’s Large Behaviors Team. Academic page: <a href="https://zt-yang.com/" target="_blank">https://zt-yang.com</a>.</p>

          </div>
        </td>
        <td>
          <p style="font-size: 12px;"><b>Abstract:</b> To enable robots to perform long-horizon manipulation tasks in diverse, complex environments—such as organizing shelf spaces or making chicken soup in various office or home settings, it is beneficial to leverage the strengths of both deep learning and model-based methods. Learning-based methods offer rapid inference, local reactivity, and large-scale knowledge from the internet, but they struggle to generate long-horizon trajectories in visually diverse and geometrically complex environments. On the other hand, Task and motion planning ensures geometric feasibility, but its computational demands become impractical as the state space and task horizon grow. Additionally, encoding domain-specific knowledge and object dynamics is often cumbersome. Neither approach alone can fully address the complexity of real-world robotic tasks in a generalizable way. To overcome these challenges, we can strategically determine which components to learn from data and which to delegate to domain-agnostic planners. This talk will explore three recent projects performed in this fashion. They address tasks with intricate temporal and geometric dependencies, such as making a chicken soup, packing a box full of objects, and rearranging office chairs in a cluttered conference room. </p></br>

          <p style="font-size: 12px;"><b>Reference Papers:</b> <br>
            <a href="https://www.roboticsproceedings.org/rss19/p061.pdf" target="_blank">[Sequence-Based Plan Feasibility Prediction for Efficient Task and Motion Planning]</a>,<br> 
            <a href="https://diffusion-ccsp.github.io/" target="_blank">[Compositional Diffusion-Based Continuous Constraint Solvers]</a>,<br>
            <a href="https://arxiv.org/abs/2410.02193" target="_blank">[Guiding Long-Horizon Task and Motion Planning with Vision Language Models]</a>,<br>
            <a href="https://arxiv.org/abs/2410.06911" target="_blank">[Combining Planning and Diffusion for Mobility with Unknown Dynamics]</a>.<br></p>

        <td></td><td></td>
      </tr>
      <tr>
        <td align=center colspan="5">No Class (Thanksgiving Break)</td>
      </tr>
      <tr>
        <td align=center colspan="5">No Class (Thanksgiving Break)</td>
      </tr>
      <tr>
        <td rowspan=4 style="vertical-align:middle;text-align:center;">Final Projects<br/></td>
        <td>Mon, Dec. 2</td>
        <td class="topic">Final Project Presentation (1) 
          <div class="subtopic"></div>
        </td>
        <td></td><td></td>

      <tr>
        <td>Wed, Dec. 4</td>
        <td class="topic">Final Project Presentation (2) 
          <div class="subtopic"></div>
        </td>
        <td></td><td></td>
      </tr>

      <tr>
        <td>Fri, Dec. 6</td>
        <td class="topic">Final Project Presentation (3) 
          <div class="subtopic"></div>
        </td>
        <td></td><td></td>
      </tr>

      </tr>
      <tr class="gray">
        <td>TBA</td>
        <td></td>
        <td></td><td><font color=#800000>Final project report/code due</font></td>
      </tr>
    </tbody>
</table>
<!-- End schedule -->
                    </font>
                  </div>
              </center>
            </section>
            <br><br>
            <section id="info" class="main">
              <center>
                <header class="major">
                  <h2>Office Hours</h2>
                </header>
<!--                   <br>
                  <style>
                    a.stafflink {
                        text-decoration: none;
                        decoration: none;
                        border-bottom: none; 
                    }
                  </style>
                  <div class="table-wrapper" style="width:90%">
                    <table>
                      <tbody><tr>
                        <td>
                          <div class="staff">
                            <div><img src="../shared/Yuan.jpg" class="staff"></div>
                            <div><b><a href="https://yyuanad.github.io/" class="stafflink" target="_blank" style="color: #2EA9DF;">Yuan Yuan</a></b></div>
                            <div>Instructor</div>
                          </div>
                        </td>                        
                        <td>
                          <div class="staff">
                            <div><img src="src/gavin.jpg" class="staff"></div>
                            <div><b><a href="https://ritengzhang.github.io/" class="stafflink" target="_blank" style="color: #2EA9DF;">Gavin</a></b></div>
                            <div>Teaching Assistant</div>
                          </div>
                        </td>

                      </tr>
                    </tbody></table>
                </div>
              </center> -->

              <center>
                <!-- <br><b>Office Hours</b><br><br> -->                
               <div class="table-wrapper" style="width:90%">
                   <table class="alt" style="width:60%">
                     <thead>
                       <tr>
                         <th style="text-align:center">Name</th>
                         <th style="text-align:center">Office hours</th>
                     </tr></thead>
                     <tr class="alternate"><td>Yuan  </td><td>Mon/Tue 3-4PM @ 245 Beacon Rm. 528E</td></tr> 
                     <tr class="alternate"><td>Lejun </td><td>M 5-6, 5-7PM if needed, W 5-6PM @ CS Lab</td></tr>
                     <tr class="alternate"><td>Yunhan </td><td>TW TH 6-7PM @ CS Lab</td></tr>
                   </tbody></table>
                    <div align="left" style="padding-left: 4%; margin-top: -30px">
                    <ul>
                        <li>Office hours will take place in person (or Zoom if needed).</li>
                        <!--- <li>Yuan will hold additional one-on-one AMA office hours Tue 4-5pm/Wed 3-4pm <a href="https://calendly.com/yyuanad/open-office-hour" target="_blank" style="color: #2EA9DF;">(15-min by appointment)</a></li> --->
                    </ul>
                    </div>
                 <br><br>
               </div>
      </center></section>


      <!-- Guest Speaker -->
<!--             <section id="staff" class="main">
              <center>
                <header class="major">
                  <h2>Guest Speakers</h2>
                </header>
                  <br>
                  <style>
                    a.stafflink {
                        text-decoration: none;
                        decoration: none;
                        border-bottom: none; 
                    }
                  </style>
                  <div class="table-wrapper" style="width:90%">
                    <table>
                      <tbody><tr>

                        <td>
                          <div class="staff">
                            <div><img src="src/ChunyuanLi.jpg" class="staff"></div>
                            <div><b><a href="https://chunyuan.li/" class="stafflink" target="_blank" style="color: #2EA9DF;">Chunyuan Li</a></b></div>
                            <div>Microsoft Research</div>
                          </div>
                        </td>  

                        <td>
                          <div class="staff">
                            <div><img src="src/TianhongLi.jpg" class="staff"></div>
                            <div><b><a href="https://www.tianhongli.me/" class="stafflink" target="_blank" style="color: #2EA9DF;">Tianhong Li</a></b></div>
                            <div>MIT CSAIL</div>
                          </div>
                        </td> 

                        <td>
                          <div class="staff">
                            <div><img src="src/GeYang.jpg" class="staff"></div>
                            <div><b><a href="https://www.episodeyang.com/" class="stafflink" target="_blank" style="color: #2EA9DF;">Ge Yang</a></b></div>
                            <div>MIT CSAIL</div>
                          </div>
                        </td>

                        <td>
                          <div class="staff">
                            <div><img src="src/Zifan_SHI.jpg" class="staff"></div>
                            <div><b><a href="https://vivianszf.github.io/" class="stafflink" target="_blank" style="color: #2EA9DF;">Zifan Shi</a></b></div>
                            <div>Stanford / HKUST</div>
                          </div>
                        </td> 


                        </tr>

                        <tr>


                        <td>
                          <div class="staff">
                            <div><img src="src/GuohaoLi.jpg" class="staff"></div>
                            <div><b><a href="https://ghli.org/" class="stafflink" target="_blank" style="color: #2EA9DF;">Guohao Li</a></b></div>
                            <div>University of Oxford</div>
                          </div>
                        </td>  

                        <td>
                          <div class="staff">
                            <div><img src="src/HanziMao.png" class="staff"></div>
                            <div><b><a href="https://hanzimao.me/" class="stafflink" target="_blank" style="color: #2EA9DF;">Hanzi Mao</a></b></div>
                            <div>Nvidia Research</div>
                          </div>
                        </td> 

                        <td>
                          <div class="staff">
                            <div><img src="src/haohemit.jpg" class="staff"></div>
                            <div><b><a href="https://scholar.google.com/citations?user=v1sUoqwAAAAJ&hl=en" class="stafflink" target="_blank" style="color: #2EA9DF;">Hao He</a></b></div>
                            <div>MIT CSAIL</div>
                          </div>
                        </td> 

                        <td>
                          <div class="staff">
                            <div><img src="src/LijieFan.jpeg" class="staff"></div>
                            <div><b><a href="http://lijiefan.me/" class="stafflink" target="_blank" style="color: #2EA9DF;">Lijie Fan</a></b></div>
                            <div>MIT CSAIL</div>
                          </div>
                        </td> 

                        
                      </tr>
                    </tbody></table>

                </div>
              </center>
            </section> -->

            
            <!-- Introduction -->
            <section id="info" class="main">
              <center>
                <header class="major">
                  <h2>Course Information</h2>
                </header>

                <div class="spotlight" style="width: 90%; text-align: left">
                    <div class="content">

                          This is a challenging course and we are here to help you become a more-AI version of yourself.
                          Please feel free to reach out if you need help in any form.
                          <br/>
                        <p><b>1. Get help</b> (besides office hours)</p>
                      <div style="padding-left: 4%; margin-top: -35px">
                        <ul>
                            <li><b>Dropbox:</b> The lecture pdfs will be uploaded to Dropbox (follow the link) and you can ask questions there by making comments on the slides directly. 
                                <li><b>Discord:</b> For labs/psets/final projects, we will create dedicated channels for you to ask public questions. 
                                If you cannot make your post public (e.g., due to
                    revealing problem set solutions), please directly DM TAs or the instructor separately,
                    or come to office
                    hours. Please note, however, that the course staff
                    cannot provide help debugging code, and there is
                    no guarantee that they'll be able to answer
                    last-minute homework questions before the
                    deadline. We also appreciate it when you respond
                    to questions from other students! If you have an
                    important question that you would prefer to discuss
                    over email, you may email the course staff, 
                    or you can contact the instructor by email
                    directly.</li>
                    <li><b>Support:</b> The <a href="https://www.bc.edu/bc-web/offices/student-affairs/sites/counseling.html">university counseling services center</a> provides
                     a variety of programs and activities.
                    </li>
                    <li>
                        <b>Accommodations for students with disabilities:</b>
                        If you are a student with a documented disability seeking reasonable accommodations in this course, please contact Kathy Duggan, (617) 552-8093, <a href="mailto:dugganka@bc.edu">dugganka@bc.edu</a>, at the Connors Family Learning Center regarding learning disabilities and ADHD, or Rory Stein, (617) 552-3470, <a href="mailto:steinr@bc.edu">steinr@bc.edu</a>, in the Disability Services Office regarding all other types of disabilities, including temporary disabilities. Advance notice and appropriate documentation are required for accommodations.
                        </li>

                        </ul>
                    </div>
                    <br/>


                    <p><b>2. Homework submission</b></p>
                      <div style="padding-left: 4%; margin-top: -35px">
                        All programming assignments are in Python on Colab, always due at
                    <b><font color=#800000>midnight (11:59 pm) on the due date</font></b>. 
                      <ul>
                        <li><b>Install Colab on the browser:</b> 
                            Sign in to your Google account, follow the "Link" (to be updated)
                            <!-- <a href="https://drive.google.com/drive/folders/1iZcw9dK6DSmKxAsErCZW3tSr479yAPFF?usp=share_link">[link]</a>  -->
                            to the folder of assignments, click on <i>lab0.ipynb</i>, click on "Open with" and "Connect more apps", install "Colaboratory".
                        <li><b>Submission:</b>
                            You need save a copy of the file in your own Google drive, so that you can save your edits. Afterwards, you can download the ipynb file and submit it to <b>Canvas</b>.</li> 
                        <!-- <li><b>Lab (1 per week):</b> 
                    Every lecture has a lab exercise to help you gain the hands-on understanding about the material. The lab on previous week's lectures is due <i>on Wednesday</i>.
                    We will go through some code in class and you need to finish up the exercises.
                        </li>
                        
                        <li><b>Pset (4 in total):</b> 
                    In each pset, we will build a working prototype for a biology lab or a healthcare startup.
                        </li> -->

                        <li><b>Final project:</b> 
                          <!-- <a href="https://docs.google.com/document/d/1Ii08EZK-BtAc4QvtNgWSHsi8cW1kUDJfmUltuvxVkH8/edit#">(guideline)</a>  -->
                          In lieu of a final exam,
                    we'll have a final project. This project will be
                    completed in small groups during the last weeks of
                    the class. The direction for this project is
                    open-ended: you can either choose from a list of
                    project ideas that we distribute, or you can
                    propose a topic of your own. A short project
                    proposal will be due approximately halfway through
                    the course.  During the final exam period, you'll
                    turn in a final report and give a short
                    presentation. You may use an ongoing research work
                    for your final project, as long it meets the
                    requirements.</li>                      
                        </ul>
                    </div>
                    <br/>
                    
                    <p><b>3. Academic policy</b></p>
                      <div style="padding-left: 4%; margin-top: -35px">
                        <ul>
                        <li><b>Late days:</b> You'll have <b> 1 late
                        day</b> for every lab and pset respectively
                        over the course of the
                        semester. Each time you use one, you may
                        submit a homework assignment one day late
                        without penalty. <!---You are allowed to use
                        multiple late days on a single assignment. For
                        example, you can use all of your days at once
                        to turn in one assignment a week late. ---> You
                        do <i>not</i> need to notify us when you use a
                        late day; we'll deduct it automatically. If
                        you run out of late days and still submit
                        late, your assignment will be penalized at a
                        rate of 2% per day. If you edit your
                        assignment after the deadline, this will count
                        as a late submission, and we'll use the
                        revision time as the date of submission (after
                        a short grace period of a few minutes). We
                        will not provide additional late time, except
                        under exceptional circumstances, and for these
                        we'll require documentation (e.g., a doctor's
                        note). Please note that the late days are
                        provided to help you deal with minor setbacks,
                        such as routine illness or injury, paper
                        deadlines, interviews, and computer problems;
                        these do not generally qualify for an
                        additional extension.</li>
                    <li><b>Academic integrity:</b> While you are
                       encouraged to discuss homework
                      assignments with other students, <i>your
                        programming work must be completed
                        individually</i>. You may not search for
                      solutions online, or to use existing
                      implementations of the algorithms in the
                      assignments. Thus it is acceptable to learn from another student the general idea for writing program code to perform a particular task, or the technique for solving a mathematical problem, but unacceptable for two students to prepare their assignments together and submit what are essentially two copies of identical work. If you have any uncertainty about the application of this policy, please check with me.
                      Failure to comply with these guidelines 
                      will be considered a violation of the 
                      <a href="https://www.bc.edu/bc-web/academics/sites/university-catalog/policies-procedures.html#academic_integrity_policies">University policies on academic integrity</a>. 
                      Please make sure that you are familiar with these policies. 
                      We will use <b><a href="https://moss.pl/">moss.pl</a></b> tool to check each lab and pset for plagriasm detection.
                    </li>

                    <li><b>AI assistants policy:</b> 
                      <ul style="margin-left: 30px;margin-top: 0px">
                      <li>Our policy for using ChatGPT and other AI assistants is identical to our policy for using human assistants.</li>
                      <li>This is a deep learning class and you should try out all the latest AI assistants (they are pretty much all using deep learning). It's very important to play with them to learn what they can do and what they can't do. That's a part of the content of this course.</li>
                      <li>Just like you can come to office hours and ask a human questions (about the lecture material, clarifications about pset questions, tips for getting started, etc), you are very welcome to do the same with AI assistants.</li>
                      <li>But: just like you are not allowed to ask an expert friend to do your homework for you, you also should not ask an expert AI.</li>
                      <li>If it is ever unclear, just imagine the AI as a human and apply the same norm as you would with a human.</li>
                    </ul>
                    </li>

                    </ul>
                    </div>
                    <br/>


 

                                        
                    <b>4. Related Classes / Online Resources</b>
                      <div style="padding-left: 4%; margin-top: 0px">
                        <ul style="padding-left: 4%;">
                          <li><a href="https://https://miayuanai.github.io/csci3399/s24/" target="_blank">CSCI 3399: Vision and Learning -- Intro to Deep Learning, BC Spring 2024</a></li>
                          <li><a href="https://phillipi.github.io/6.s898/" target="_blank">6.S898 Deep Learning, MIT EECS</a></li>
                          <li><a href="http://cs231n.stanford.edu/" target="_blank">CS231n Convolutional Neural Networks for Visual Recognition, Stanford</a></li>
                          <li><a href="https://deeplearning.cs.cmu.edu/S24/index.html" target="_blank">Deep Learning, CMU</a></li>
                          <li><a href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/" target="_blank">Machine Learning, Oxford</a></li>
                          <li><a href="https://www.youtube.com/user/GoogleTechTalks/deep_learning_nyu_spring_2014" target="_blank">Deep Learning, New York University</a></li>
                          <li><a href="https://www.cs.umd.edu/~djacobs/CMSC828DeepLearning/Syllabus.htm" target="_blank">Deep Learning, University of Maryland</a></li>
                          <li><a href="https://sites.cc.gatech.edu/classes/AY2024/cs7643_fall/" target="_blank">Deep Learning, Georgia Tech</a></li>




                            
                        </ul>
                    </div>
                    <br/>
               
                    <b>Acknowledgements:</b> This course draws
                       heavily from MIT's <a href="http://6.869.csail.mit.edu/fa14/">6.869:
                       Advances in Computer Vision</a> by Antonio
                       Torralba, William Freeman, and Phillip
                       Isola, and from Stanford's <a href="http://cs231n.stanford.edu/schedule.html">CS231n: Deep Learning for Computer Vision</a> by Fei-Fei Li. It also includes lecture slides from
                       other researchers, including <a href="https://andrewowens.com/">Andrew Owens
                       </a>, <a href="http://slazebni.cs.illinois.edu/">Svetlana
                       Lazebnik</a>, <a href="https://people.eecs.berkeley.edu/~efros/">Alexei
                       Efros</a>,  <a href="https://profiles.stanford.edu/fei-fei-li">Fei-fei
                       Li</a>,  <a href="https://www.cs.columbia.edu/~vondrick/">Carl
                       Vondrick</a>,  <a href="https://web.eecs.umich.edu/~fouhey/">David
                       Fouhey</a>, <a href="https://web.eecs.umich.edu/~justincj/">Justin Johnson</a>, and <a href="http://www.cs.cornell.edu/~snavely">Noah
                       Snavely</a>, <a href="http://introtodeeplearning.com/">David
                       Fouhey and Ava Amini</a>. 
                   Special thanks to <a href="http://www.wanghao.in/index.html">Hao Wang</a> for the insightful and generous advice.
                    </div>
              </div></center>
            </section>

          <!-- Footer -->
            <footer id="footer">
              <p class="copyright"><font size="-1">© 2024
              Boston College. Website based on a template
              from <a href="https://html5up.net/">HTML5
                  Up</a>, Andrew Owen's <a href="https://www.eecs.umich.edu/courses/eecs442-ahowens/fa20/">course</a> at U. Michigan, and Donglai Wei's <a href="https://bc-cv.github.io/csci3343/f22/">course</a> at Boston College.
          </font></p></footer><font size="-1">
      </font></section></div><font size="-1">

      <script src="../shared/jquery.min.js"></script>
      <script src="../shared/jquery.scrollex.min.js"></script>
      <script src="../shared/jquery.scrolly.min.js"></script>
      <script src="../shared/skel.min.js"></script>
      <script src="../shared/util.js"></script>

</font></div></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>
